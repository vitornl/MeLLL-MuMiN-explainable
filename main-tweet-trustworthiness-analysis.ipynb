{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "from graphlime import GraphLIME\n",
    "from mumin import MuminDataset\n",
    "\n",
    "import torchmetrics as tm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch_geometric.data import Data as tgData\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from mumin_explainable.architectures.graphs import GAT\n",
    "from mumin_explainable.processor.tweetnormalizer import normalizeTweet\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import mlflow\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "_= torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup mumin graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-25 08:30:53,600 [INFO] Loading dataset\n",
      "2023-08-25 08:31:56,689 [INFO] Outputting to DGL\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'article': 1446, 'claim': 2083, 'hashtag': 27802, 'image': 1015, 'reply': 177816, 'tweet': 4061, 'user': 152038},\n",
       "      num_edges={('article', 'has_article_inv', 'tweet'): 1890, ('claim', 'discusses_inv', 'tweet'): 4749, ('hashtag', 'has_hashtag_inv', 'tweet'): 2284, ('hashtag', 'has_hashtag_inv', 'user'): 49626, ('image', 'has_image_inv', 'tweet'): 1019, ('reply', 'posted_inv', 'user'): 177816, ('reply', 'quote_of', 'tweet'): 88495, ('reply', 'reply_to', 'tweet'): 78576, ('tweet', 'discusses', 'claim'): 4749, ('tweet', 'has_article', 'article'): 1890, ('tweet', 'has_hashtag', 'hashtag'): 2284, ('tweet', 'has_image', 'image'): 1019, ('tweet', 'mentions', 'user'): 1112, ('tweet', 'posted_inv', 'user'): 4061, ('tweet', 'quote_of_inv', 'reply'): 88495, ('tweet', 'reply_to_inv', 'reply'): 78576, ('tweet', 'retweeted_inv', 'user'): 12800, ('user', 'follows', 'user'): 17974, ('user', 'follows_inv', 'user'): 17974, ('user', 'has_hashtag', 'hashtag'): 49626, ('user', 'mentions', 'user'): 2762, ('user', 'mentions_inv', 'tweet'): 1112, ('user', 'mentions_inv', 'user'): 2762, ('user', 'posted', 'reply'): 177816, ('user', 'posted', 'tweet'): 4061, ('user', 'retweeted', 'tweet'): 12800},\n",
       "      metagraph=[('article', 'tweet', 'has_article_inv'), ('tweet', 'claim', 'discusses'), ('tweet', 'article', 'has_article'), ('tweet', 'hashtag', 'has_hashtag'), ('tweet', 'image', 'has_image'), ('tweet', 'user', 'mentions'), ('tweet', 'user', 'posted_inv'), ('tweet', 'user', 'retweeted_inv'), ('tweet', 'reply', 'quote_of_inv'), ('tweet', 'reply', 'reply_to_inv'), ('claim', 'tweet', 'discusses_inv'), ('hashtag', 'tweet', 'has_hashtag_inv'), ('hashtag', 'user', 'has_hashtag_inv'), ('user', 'user', 'follows'), ('user', 'user', 'follows_inv'), ('user', 'user', 'mentions'), ('user', 'user', 'mentions_inv'), ('user', 'hashtag', 'has_hashtag'), ('user', 'tweet', 'mentions_inv'), ('user', 'tweet', 'posted'), ('user', 'tweet', 'retweeted'), ('user', 'reply', 'posted'), ('image', 'tweet', 'has_image_inv'), ('reply', 'user', 'posted_inv'), ('reply', 'tweet', 'quote_of'), ('reply', 'tweet', 'reply_to')])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size= 'small'\n",
    "dataset_mumin = MuminDataset(\n",
    "    twitter_bearer_token=os.getenv('TWITTER_BEARER_TOKEN'),\n",
    "    size=size,\n",
    "    dataset_path=f'./data/datasets/mumin-{size}.zip'\n",
    ")\n",
    "dataset_mumin.compile()\n",
    "mumin_graph = dataset_mumin.to_dgl()\n",
    "mumin_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = dataset_mumin.nodes['user']\n",
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "\n",
    "user_posted_tweet_df = dataset_mumin.rels[('user', 'posted', 'tweet')]\n",
    "user_posted_tweet_subgraph = dgl.edge_type_subgraph(mumin_graph, etypes=[('user', 'posted', 'tweet')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = 'multilingual'\n",
    "tweet_ds_copy = dataset_mumin.nodes['tweet'].dropna()\n",
    "lang_tweets = (tweet_ds_copy['lang'] == LANG).to_list()\n",
    "del(tweet_ds_copy)\n",
    "\n",
    "if LANG == 'multilingual':\n",
    "    lang_tweets = [True] * len(lang_tweets)\n",
    "tweet_train_mask = user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets)\n",
    "tweet_val_mask = user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets)\n",
    "tweet_test_mask = user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_index = torch.cat([\n",
    "    user_posted_tweet_subgraph.edges(etype='posted')[0].unsqueeze(0),\n",
    "    user_posted_tweet_subgraph.edges(etype='posted')[1].unsqueeze(0)\n",
    "], dim=0)\n",
    "data = tgData(\n",
    "    x=user_posted_tweet_subgraph.nodes['tweet'].data['feat'],\n",
    "    y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=tweet_train_mask,\n",
    "    val_mask=tweet_val_mask,\n",
    "    test_mask=tweet_test_mask,\n",
    "    edge_index=edges_index.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance with text-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "TEXT_DIM = 100\n",
    "\n",
    "LANG_TOOL_MAP = {\n",
    "    'multilingual': {\n",
    "        'bertweet': AutoModel.from_pretrained('vinai/bertweet-base'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('vinai/bertweet-base', use_fast=False)\n",
    "    },\n",
    "    'en': {\n",
    "        'bertweet': AutoModel.from_pretrained('vinai/bertweet-base'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('vinai/bertweet-base', use_fast=False)\n",
    "    },\n",
    "    'pt': {\n",
    "        'bertweet': AutoModel.from_pretrained('melll-uff/bertweetbr'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('melll-uff/bertweetbr', normalization=True)\n",
    "    },\n",
    "    'es': {\n",
    "        'bertweet': AutoModel.from_pretrained('pysentimiento/robertuito-base-cased'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('pysentimiento/robertuito-base-cased')\n",
    "    }\n",
    "}\n",
    "\n",
    "bertweet = LANG_TOOL_MAP[LANG]['bertweet']\n",
    "tokenizer = LANG_TOOL_MAP[LANG]['tokenizer']\n",
    "\n",
    "def tweetencoder(x, text_dim):\n",
    "    try:\n",
    "        x = bertweet(torch.tensor([tokenizer.encode(normalizeTweet(x))])).pooler_output\n",
    "    except:\n",
    "        x = bertweet(torch.tensor([tokenizer.encode('')])).pooler_output\n",
    "    return nn.Linear(768, text_dim)(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['text_encoding'] = str([0] * TEXT_DIM)\n",
    "if LANG == 'multilingual':\n",
    "    tweet_df['text_encoding'] = [tweetencoder(text, TEXT_DIM) for text in tweet_df['text']]\n",
    "else:\n",
    "    tweet_df['text_encoding'] = [tweetencoder(text, TEXT_DIM) if lang == LANG else str([0] * TEXT_DIM) for text,lang in zip(tweet_df['text'], tweet_df['lang'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>source</th>\n",
       "      <th>num_retweets</th>\n",
       "      <th>num_replies</th>\n",
       "      <th>num_quote_tweets</th>\n",
       "      <th>text_emb</th>\n",
       "      <th>lang_emb</th>\n",
       "      <th>...</th>\n",
       "      <th>emb90</th>\n",
       "      <th>emb91</th>\n",
       "      <th>emb92</th>\n",
       "      <th>emb93</th>\n",
       "      <th>emb94</th>\n",
       "      <th>emb95</th>\n",
       "      <th>emb96</th>\n",
       "      <th>emb97</th>\n",
       "      <th>emb98</th>\n",
       "      <th>emb99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1238947475471454220</td>\n",
       "      <td>Antes de llegar a los pulmones dura 4 d√≠as en ...</td>\n",
       "      <td>2020-03-14 21:57:51</td>\n",
       "      <td>es</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0467078, 0.25795, 0.119816095, 0.4975067, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.126746</td>\n",
       "      <td>0.073426</td>\n",
       "      <td>0.018710</td>\n",
       "      <td>-0.030212</td>\n",
       "      <td>0.033471</td>\n",
       "      <td>-0.057429</td>\n",
       "      <td>-0.227508</td>\n",
       "      <td>-0.088288</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>0.114474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1295062953000042496</td>\n",
       "      <td>Aeroporto de Dubai em chamas. ü§ïüòß https://t.co/...</td>\n",
       "      <td>2020-08-16 18:20:43</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.04832051, 0.22119147, 0.10080599, 0.506648...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070786</td>\n",
       "      <td>0.184929</td>\n",
       "      <td>-0.058850</td>\n",
       "      <td>0.004570</td>\n",
       "      <td>0.048659</td>\n",
       "      <td>0.096716</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>-0.073876</td>\n",
       "      <td>0.015296</td>\n",
       "      <td>0.127499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1294614020008312832</td>\n",
       "      <td>Fogo üî• no aeroporto de Dubai üò±üò± https://t.co/2...</td>\n",
       "      <td>2020-08-15 12:36:49</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>24</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>[-0.049368992, 0.20724605, 0.09472715, 0.51769...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081196</td>\n",
       "      <td>0.013280</td>\n",
       "      <td>0.029083</td>\n",
       "      <td>0.077871</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>0.023791</td>\n",
       "      <td>0.020638</td>\n",
       "      <td>0.101853</td>\n",
       "      <td>-0.089112</td>\n",
       "      <td>-0.006730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1294701863489744896</td>\n",
       "      <td>Fogo no aeroporto de Dubai. https://t.co/yhQDe...</td>\n",
       "      <td>2020-08-15 18:25:53</td>\n",
       "      <td>pt</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>[-0.054105558, 0.22766814, 0.09675161, 0.51384...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020154</td>\n",
       "      <td>-0.046229</td>\n",
       "      <td>-0.083547</td>\n",
       "      <td>0.131931</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>-0.098313</td>\n",
       "      <td>-0.019943</td>\n",
       "      <td>-0.003674</td>\n",
       "      <td>0.061658</td>\n",
       "      <td>-0.061630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1295124644085805057</td>\n",
       "      <td>Incendio en el aeropuerto de Dubai https://t.c...</td>\n",
       "      <td>2020-08-16 22:25:52</td>\n",
       "      <td>es</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.043678686, 0.23453882, 0.11631639, 0.50836...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037292</td>\n",
       "      <td>0.022898</td>\n",
       "      <td>-0.079963</td>\n",
       "      <td>0.111332</td>\n",
       "      <td>-0.128751</td>\n",
       "      <td>0.083455</td>\n",
       "      <td>-0.012020</td>\n",
       "      <td>-0.061838</td>\n",
       "      <td>-0.022083</td>\n",
       "      <td>-0.029660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4056</th>\n",
       "      <td>783488210454376448</td>\n",
       "      <td>Yes,  @ClintonFdn has accepted millions from f...</td>\n",
       "      <td>2016-10-05 02:05:20</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>270</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>[-0.055992845, 0.23851915, 0.12183203, 0.51381...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045623</td>\n",
       "      <td>-0.122109</td>\n",
       "      <td>-0.088662</td>\n",
       "      <td>-0.004221</td>\n",
       "      <td>0.017393</td>\n",
       "      <td>-0.072896</td>\n",
       "      <td>-0.119485</td>\n",
       "      <td>0.111239</td>\n",
       "      <td>-0.140027</td>\n",
       "      <td>-0.025499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057</th>\n",
       "      <td>783486380777373696</td>\n",
       "      <td>#VPDebate fact check: Yes, the Clinton Foundat...</td>\n",
       "      <td>2016-10-05 01:58:04</td>\n",
       "      <td>en</td>\n",
       "      <td>SocialFlow</td>\n",
       "      <td>227</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>[-0.066264085, 0.2269559, 0.11466829, 0.508162...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.143425</td>\n",
       "      <td>0.006828</td>\n",
       "      <td>0.082407</td>\n",
       "      <td>-0.148371</td>\n",
       "      <td>-0.060529</td>\n",
       "      <td>0.064475</td>\n",
       "      <td>0.102566</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>-0.128234</td>\n",
       "      <td>-0.075311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4058</th>\n",
       "      <td>783493825931206656</td>\n",
       "      <td>Yes, the Clinton Foundation has accepted milli...</td>\n",
       "      <td>2016-10-05 02:27:39</td>\n",
       "      <td>en</td>\n",
       "      <td>Twitter Web Client</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.054452505, 0.23137671, 0.1135482, 0.503517...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.033770</td>\n",
       "      <td>-0.064164</td>\n",
       "      <td>0.016560</td>\n",
       "      <td>0.049262</td>\n",
       "      <td>-0.016212</td>\n",
       "      <td>-0.099194</td>\n",
       "      <td>0.010516</td>\n",
       "      <td>-0.031040</td>\n",
       "      <td>0.071047</td>\n",
       "      <td>0.125053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4059</th>\n",
       "      <td>1337737596881911809</td>\n",
       "      <td>üìå ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏£‡∏Ñ‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÑ‡∏ß‡∏£‡∏±‡∏™‡πÇ‡∏Ñ‡πÇ‡∏£‡∏ô‡∏≤ 2019 (COVID-...</td>\n",
       "      <td>2020-12-12 12:34:31</td>\n",
       "      <td>th</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[-0.06284507, 0.2391499, 0.11289272, 0.5124814...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041474</td>\n",
       "      <td>0.088375</td>\n",
       "      <td>0.057698</td>\n",
       "      <td>0.025241</td>\n",
       "      <td>0.161460</td>\n",
       "      <td>-0.095974</td>\n",
       "      <td>0.194330</td>\n",
       "      <td>-0.131195</td>\n",
       "      <td>0.001408</td>\n",
       "      <td>0.137069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4060</th>\n",
       "      <td>1366861014743056389</td>\n",
       "      <td>We mochten terug beelden ontvangen van een jon...</td>\n",
       "      <td>2021-03-02 21:20:35</td>\n",
       "      <td>nl</td>\n",
       "      <td>Blog2Social APP</td>\n",
       "      <td>11</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.048639365, 0.24228735, 0.10824736, 0.50258...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040195</td>\n",
       "      <td>0.191438</td>\n",
       "      <td>-0.055116</td>\n",
       "      <td>0.137664</td>\n",
       "      <td>-0.155272</td>\n",
       "      <td>-0.014646</td>\n",
       "      <td>0.125681</td>\n",
       "      <td>-0.058634</td>\n",
       "      <td>0.099958</td>\n",
       "      <td>0.292839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4061 rows √ó 111 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id                                               text  \\\n",
       "0     1238947475471454220  Antes de llegar a los pulmones dura 4 d√≠as en ...   \n",
       "1     1295062953000042496  Aeroporto de Dubai em chamas. ü§ïüòß https://t.co/...   \n",
       "2     1294614020008312832  Fogo üî• no aeroporto de Dubai üò±üò± https://t.co/2...   \n",
       "3     1294701863489744896  Fogo no aeroporto de Dubai. https://t.co/yhQDe...   \n",
       "4     1295124644085805057  Incendio en el aeropuerto de Dubai https://t.c...   \n",
       "...                   ...                                                ...   \n",
       "4056   783488210454376448  Yes,  @ClintonFdn has accepted millions from f...   \n",
       "4057   783486380777373696  #VPDebate fact check: Yes, the Clinton Foundat...   \n",
       "4058   783493825931206656  Yes, the Clinton Foundation has accepted milli...   \n",
       "4059  1337737596881911809  üìå ‡∏™‡∏ñ‡∏≤‡∏ô‡∏Å‡∏≤‡∏£‡∏ì‡πå‡πÇ‡∏£‡∏Ñ‡∏ï‡∏¥‡∏î‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡πÑ‡∏ß‡∏£‡∏±‡∏™‡πÇ‡∏Ñ‡πÇ‡∏£‡∏ô‡∏≤ 2019 (COVID-...   \n",
       "4060  1366861014743056389  We mochten terug beelden ontvangen van een jon...   \n",
       "\n",
       "              created_at lang               source  num_retweets  num_replies  \\\n",
       "0    2020-03-14 21:57:51   es  Twitter for Android             8            3   \n",
       "1    2020-08-16 18:20:43   pt  Twitter for Android             6            0   \n",
       "2    2020-08-15 12:36:49   pt  Twitter for Android            24           11   \n",
       "3    2020-08-15 18:25:53   pt  Twitter for Android            15            7   \n",
       "4    2020-08-16 22:25:52   es  Twitter for Android            33            5   \n",
       "...                  ...  ...                  ...           ...          ...   \n",
       "4056 2016-10-05 02:05:20   en   Twitter Web Client           270           10   \n",
       "4057 2016-10-05 01:58:04   en           SocialFlow           227           23   \n",
       "4058 2016-10-05 02:27:39   en   Twitter Web Client             6            0   \n",
       "4059 2020-12-12 12:34:31   th  Twitter for Android            39            0   \n",
       "4060 2021-03-02 21:20:35   nl      Blog2Social APP            11           22   \n",
       "\n",
       "      num_quote_tweets                                           text_emb  \\\n",
       "0                    0  [-0.0467078, 0.25795, 0.119816095, 0.4975067, ...   \n",
       "1                    5  [-0.04832051, 0.22119147, 0.10080599, 0.506648...   \n",
       "2                    7  [-0.049368992, 0.20724605, 0.09472715, 0.51769...   \n",
       "3                    4  [-0.054105558, 0.22766814, 0.09675161, 0.51384...   \n",
       "4                    3  [-0.043678686, 0.23453882, 0.11631639, 0.50836...   \n",
       "...                ...                                                ...   \n",
       "4056                 3  [-0.055992845, 0.23851915, 0.12183203, 0.51381...   \n",
       "4057                23  [-0.066264085, 0.2269559, 0.11466829, 0.508162...   \n",
       "4058                 1  [-0.054452505, 0.23137671, 0.1135482, 0.503517...   \n",
       "4059                 5  [-0.06284507, 0.2391499, 0.11289272, 0.5124814...   \n",
       "4060                 0  [-0.048639365, 0.24228735, 0.10824736, 0.50258...   \n",
       "\n",
       "                                               lang_emb  ...     emb90  \\\n",
       "0     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  ...  0.126746   \n",
       "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...  0.070786   \n",
       "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ... -0.081196   \n",
       "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ... -0.020154   \n",
       "4     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ...  ...  0.037292   \n",
       "...                                                 ...  ...       ...   \n",
       "4056  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  ... -0.045623   \n",
       "4057  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  ...  0.143425   \n",
       "4058  [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, ...  ...  0.033770   \n",
       "4059  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ...  0.041474   \n",
       "4060  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ... -0.040195   \n",
       "\n",
       "         emb91     emb92     emb93     emb94     emb95     emb96     emb97  \\\n",
       "0     0.073426  0.018710 -0.030212  0.033471 -0.057429 -0.227508 -0.088288   \n",
       "1     0.184929 -0.058850  0.004570  0.048659  0.096716  0.030813 -0.073876   \n",
       "2     0.013280  0.029083  0.077871  0.031103  0.023791  0.020638  0.101853   \n",
       "3    -0.046229 -0.083547  0.131931  0.195300 -0.098313 -0.019943 -0.003674   \n",
       "4     0.022898 -0.079963  0.111332 -0.128751  0.083455 -0.012020 -0.061838   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4056 -0.122109 -0.088662 -0.004221  0.017393 -0.072896 -0.119485  0.111239   \n",
       "4057  0.006828  0.082407 -0.148371 -0.060529  0.064475  0.102566  0.012263   \n",
       "4058 -0.064164  0.016560  0.049262 -0.016212 -0.099194  0.010516 -0.031040   \n",
       "4059  0.088375  0.057698  0.025241  0.161460 -0.095974  0.194330 -0.131195   \n",
       "4060  0.191438 -0.055116  0.137664 -0.155272 -0.014646  0.125681 -0.058634   \n",
       "\n",
       "         emb98     emb99  \n",
       "0     0.034988  0.114474  \n",
       "1     0.015296  0.127499  \n",
       "2    -0.089112 -0.006730  \n",
       "3     0.061658 -0.061630  \n",
       "4    -0.022083 -0.029660  \n",
       "...        ...       ...  \n",
       "4056 -0.140027 -0.025499  \n",
       "4057 -0.128234 -0.075311  \n",
       "4058  0.071047  0.125053  \n",
       "4059  0.001408  0.137069  \n",
       "4060  0.099958  0.292839  \n",
       "\n",
       "[4061 rows x 111 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_embedding_columns = [f'emb{i}' for i in range(TEXT_DIM)]\n",
    "\n",
    "tweet_embeddings_split_df = pd.DataFrame(\n",
    "    [x if not isinstance(x, str) else eval(x) for x in tweet_df['text_encoding'].tolist()],\n",
    "    index=tweet_df.index,\n",
    "    columns=new_embedding_columns\n",
    ")\n",
    "tweet_df = pd.concat([tweet_df, tweet_embeddings_split_df], axis=1)\n",
    "tweet_df.dropna(inplace=True)\n",
    "display(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'multimodal'\n",
    "\n",
    "new_features_df = pd.DataFrame(index=range(user_posted_tweet_subgraph.nodes['tweet'].data['feat'].shape[0]))\n",
    "new_features_df = new_features_df.join(tweet_df[new_embedding_columns])#.fillna(0)\n",
    "new_features_tensor = torch.tensor(new_features_df.values).double()\n",
    "\n",
    "mixed_features = new_features_tensor\n",
    "if MODE == 'multimodal':\n",
    "    mixed_features = torch.cat([user_posted_tweet_subgraph.nodes['tweet'].data['feat'], new_features_tensor], axis = 1).double()\n",
    "\n",
    "edges_index = torch.cat([\n",
    "    user_posted_tweet_subgraph.edges(etype='posted')[0].unsqueeze(0),\n",
    "    user_posted_tweet_subgraph.edges(etype='posted')[1].unsqueeze(0)\n",
    "], dim=0)\n",
    "new_features_data = tgData(\n",
    "    x=mixed_features,\n",
    "    y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets),\n",
    "    val_mask=user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets),\n",
    "    test_mask=user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets),\n",
    "    edge_index=edges_index.long())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trustworthy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_features_data_x_mim = torch.ones((new_features_data.x.shape[0], new_features_data.x.shape[1], 2))\n",
    "# new_features_data_x_mim[:,:,0] = new_features_data.x\n",
    "# new_features_data_x_mim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test original_features\n"
     ]
    }
   ],
   "source": [
    "hparams = {\n",
    "    'input_dim': new_features_data.num_node_features,\n",
    "    'hidden_dim': 16,\n",
    "    'output_dim': max(new_features_data.y).item() + 1\n",
    "}\n",
    "\n",
    "model = GAT(**hparams).double()\n",
    "\n",
    "MODEL_NAME = f'multilingual_multimodal'\n",
    "\n",
    "model.load_state_dict(torch.load(f'./data/models/{MODEL_NAME}.pth'))\n",
    "model.eval()\n",
    "\n",
    "print('test original_features')\n",
    "\n",
    "original_features_classification_output = model(new_features_data.x, new_features_data.edge_index)\n",
    "probas = original_features_classification_output.exp()\n",
    "original_pred_label = torch.argmax(probas, dim=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trustworthy_features_list = random.sample(range(new_features_data.x.shape[1]), k=int(new_features_data.x.shape[1] * 0.7))\n",
    "untrustworthy_features_list = [i for i in range(new_features_data.x.shape[1]) if i not in trustworthy_features_list]\n",
    "\n",
    "# trustworthy_features_mask = torch.zeros(new_features_data.x.shape[1], dtype=torch.bool)\n",
    "# untrustworthy_features_mask = torch.zeros(new_features_data.x.shape[1], dtype=torch.bool)\n",
    "# trustworthy_features_mask[trustworthy_features_list] = True\n",
    "# untrustworthy_features_mask[untrustworthy_features_list] = True\n",
    "\n",
    "# trustworthy_features = new_features_data.x[:, trustworthy_features_list]\n",
    "# untrustworthy_features = new_features_data.x[:, untrustworthy_features_list]\n",
    "\n",
    "untrustworthy_features = copy.deepcopy(new_features_data.x)\n",
    "untrustworthy_features[:,untrustworthy_features_list] = 0\n",
    "\n",
    "untrustworthy_features_data = tgData(\n",
    "    x=untrustworthy_features,\n",
    "    y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets),\n",
    "    val_mask=user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets),\n",
    "    test_mask=user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets),\n",
    "    edge_index=edges_index.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_preds = torch.argmax(model(new_features_data.x, new_features_data.edge_index)[new_features_data.test_mask].exp(), dim=1)\n",
    "untrustworthy_preds = torch.argmax(model(untrustworthy_features_data.x, untrustworthy_features_data.edge_index)[untrustworthy_features_data.test_mask].exp(), dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### no mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_preds = torch.argmax(model(new_features_data.x, new_features_data.edge_index).exp(), dim=1)\n",
    "untrustworthy_preds = torch.argmax(model(untrustworthy_features_data.x, untrustworthy_features_data.edge_index).exp(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_preds_size = []\n",
    "mistrust_idx = np.argwhere(original_preds != untrustworthy_preds).flatten()\n",
    "print(f'Number of suspect predictions {len(mistrust_idx)}')\n",
    "shouldnt_trust = set(mistrust_idx)\n",
    "flipped_preds_size.append(len(shouldnt_trust))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "mistrust = collections.defaultdict(lambda:set())\n",
    "trust = collections.defaultdict(lambda: set())\n",
    "trust_fn = lambda prev, curr: (prev > 0.5 and curr > 0.5) or (prev <= 0.5 and curr <= 0.5)\n",
    "trust_fn_all = lambda exp, unt: len([x[0] for x in exp if x[0] in unt]) == 0\n",
    "\n",
    "graphlime = GraphLIME(model, hop=2, rho=0.1, cached=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topk = 100\n",
    "num_noise_feats = []\n",
    "\n",
    "for i in range(new_features_data.x.shape[0]):\n",
    "    \n",
    "    coefs_originals = graphlime.explain_node(i, untrustworthy_features_data.x, untrustworthy_features_data.edge_index)\n",
    "    coefs_originals = np.abs(coefs_originals)\n",
    "\n",
    "    coefs_untrust = graphlime.explain_node(i, untrustworthy_features_data.x, untrustworthy_features_data.edge_index)\n",
    "    coefs_untrust = np.abs(coefs_untrust)\n",
    "\n",
    "    ### debug\n",
    "    if np.where(coefs_originals != 0)[0] != []:\n",
    "        print(feat_indices)\n",
    "        print(num_noise_feat)\n",
    "        print([untrustworthy_features_data.x.shape[0] for idx in feat_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(filter(lambda x: x != 0, num_noise_feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistrust_idx.shape, untrustworthy_features_data.x.shape, new_features_data.x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistrust_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shouldnt_trust = set(mistrust_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shouldnt_trust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ignore below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filtered.load_state_dict(torch.load(f'./data/models/{MODEL_NAME}.pth'))\n",
    "model_filtered.eval()\n",
    "\n",
    "accuracy = tm.Accuracy(task='multiclass', num_classes=2, average='none')\n",
    "stats_score = tm.StatScores(task='multiclass', num_classes=2, average='none')\n",
    "precision = tm.Precision(task='multiclass', num_classes=2, average='none')\n",
    "recall = tm.Recall(task='multiclass', num_classes=2, average='none')\n",
    "f1_score = tm.classification.f_beta.F1Score(task='multiclass', num_classes=2, average='none')\n",
    "\n",
    "print('test')\n",
    "\n",
    "output = model_filtered(trustworthy_features_data.x, trustworthy_features_data.edge_index)\n",
    "\n",
    "f1 = f1_score(output[trustworthy_features_data.test_mask], trustworthy_features_data.y[trustworthy_features_data.test_mask])\n",
    "f1macro = torch.mean(f1)\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy': accuracy(output[trustworthy_features_data.test_mask], trustworthy_features_data.y[trustworthy_features_data.test_mask]),\n",
    "    'Precision': precision(output[new_features_data.test_mask], trustworthy_features_data.y[trustworthy_features_data.test_mask]),\n",
    "    'Recall': recall(output[trustworthy_features_data.test_mask], trustworthy_features_data.y[trustworthy_features_data.test_mask]),\n",
    "    'Stats_Score': stats_score(output[trustworthy_features_data.test_mask], trustworthy_features_data.y[trustworthy_features_data.test_mask]),\n",
    "    'F1': f1,\n",
    "    'F1-macro': f1macro,\n",
    "    'Bootstrap': bootstrap.compute()\n",
    "}\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = f'{LANG}_{MODE}_filtered'\n",
    "\n",
    "model_filtered.load_state_dict(torch.load(f'./data/models/{MODEL_NAME}.pth'))\n",
    "model_filtered.eval()\n",
    "\n",
    "print('test trustworthy_features')\n",
    "\n",
    "trustworthy_features_classification_output = model_filtered(trustworthy_features_data.x, trustworthy_features_data.edge_index)\n",
    "trustworthy_pred_label = torch.argmax(trustworthy_features_classification_output.exp(), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where((original_pred_label == trustworthy_pred_label).numpy() == False)[0].shape, np.where((original_pred_label == trustworthy_pred_label).numpy() == True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_original = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "explainer_filtered = GraphLIME(model_filtered, hop=2, rho=0.1, cached=True)\n",
    "\n",
    "count_untrustworthy = 0\n",
    "for i in list(np.stack(np.argwhere((original_pred_label == trustworthy_pred_label).numpy() == False),axis=1)[0]):\n",
    "    \n",
    "    coefs_original = explainer_original.explain_node(int(i), new_features_data.x, new_features_data.edge_index)\n",
    "    coefs_filtered = explainer_filtered.explain_node(int(i), trustworthy_features_data.x, trustworthy_features_data.edge_index)\n",
    "    \n",
    "    count_untrustworthy += 1 if np.where(coefs_original != 0)[0].shape == np.where(coefs_filtered != 0)[0].shape else 0\n",
    "\n",
    "count_trustworthy = int(np.stack(np.argwhere((original_pred_label == trustworthy_pred_label).numpy() == False),axis=1)[0].shape[0]) - count_untrustworthy\n",
    "print(count_untrustworthy, count_trustworthy)\n",
    "\n",
    "100 - count_untrustworthy/len(original_pred_label)*100, 100 - count_trustworthy/len(original_pred_label)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_original = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "\n",
    "with open('count_untrustworthy.txt', 'w') as f:\n",
    "    f.write('idx,count_untrustworthy,count_trustworthy\\n')\n",
    "\n",
    "MODEL_NAME = f'{LANG}_{MODE}_filtered'\n",
    "lr = 0.005\n",
    "epochs = 400\n",
    "MAX_SAMPLES = 100\n",
    "\n",
    "for sample_iter in tqdm(range(MAX_SAMPLES)):\n",
    "    trustworthy_features_list = random.sample(range(new_features_data.x.shape[1]), k=int(new_features_data.x.shape[1] * 0.7))\n",
    "    untrustworthy_features_list = [i for i in range(new_features_data.x.shape[1]) if i not in trustworthy_features_list]\n",
    "\n",
    "    trustworthy_features = new_features_data.x[:, trustworthy_features_list]\n",
    "    untrustworthy_features = new_features_data.x[:, untrustworthy_features_list]\n",
    "\n",
    "    trustworthy_features_data = tgData(\n",
    "        x=trustworthy_features,\n",
    "        y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "        train_mask=user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets),\n",
    "        val_mask=user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets),\n",
    "        test_mask=user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets),\n",
    "        edge_index=edges_index.long())\n",
    "\n",
    "    hparams = {\n",
    "        'input_dim': trustworthy_features_data.num_node_features,\n",
    "        'hidden_dim': 16,\n",
    "        'output_dim': max(trustworthy_features_data.y).item() + 1\n",
    "    }\n",
    "\n",
    "    model_filtered = GAT(**hparams).double()\n",
    "\n",
    "    model_filtered.train()\n",
    "    optimizer = optim.Adam(model_filtered.parameters(), lr=lr)\n",
    "\n",
    "    f1_score = tm.classification.f_beta.F1Score(task='multiclass', num_classes=2, average='none')\n",
    "    best_f1macro = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model_filtered(trustworthy_features_data.x, trustworthy_features_data.edge_index)\n",
    "        loss = F.nll_loss(output[trustworthy_features_data.train_mask], trustworthy_features_data.y[trustworthy_features_data.train_mask])\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        f1 = f1_score(output[trustworthy_features_data.train_mask], trustworthy_features_data.y[trustworthy_features_data.train_mask])\n",
    "        f1macro = torch.mean(f1)\n",
    "\n",
    "        if f1macro > best_f1macro:\n",
    "            best_f1macro = f1macro\n",
    "            torch.save(model_filtered.state_dict(), f'./data/models/{MODEL_NAME}.pth')\n",
    "\n",
    "    model_filtered.eval()\n",
    "\n",
    "    trustworthy_features_classification_output = model_filtered(trustworthy_features_data.x, trustworthy_features_data.edge_index)\n",
    "    trustworthy_pred_label = torch.argmax(trustworthy_features_classification_output.exp(), dim=1)\n",
    "\n",
    "    explainer_filtered = GraphLIME(model_filtered, hop=2, rho=0.1, cached=True)\n",
    "\n",
    "    count_untrustworthy = 0\n",
    "    for i in list(np.stack(np.argwhere((original_pred_label == trustworthy_pred_label).numpy() == False),axis=1)[0]):\n",
    "        \n",
    "        coefs_original = explainer_original.explain_node(int(i), new_features_data.x, new_features_data.edge_index)\n",
    "        coefs_filtered = explainer_filtered.explain_node(int(i), trustworthy_features_data.x, trustworthy_features_data.edge_index)\n",
    "        \n",
    "        count_untrustworthy += 1 if np.where(coefs_original != 0)[0].shape == np.where(coefs_filtered != 0)[0].shape else 0\n",
    "\n",
    "    count_trustworthy = int(np.stack(np.argwhere((original_pred_label == trustworthy_pred_label).numpy() == False),axis=1)[0].shape[0]) - count_untrustworthy\n",
    "\n",
    "    result_count_untrustworthy = 100 - count_untrustworthy/len(original_pred_label)\n",
    "    result_count_trustworthy = 100 - count_trustworthy/len(original_pred_label)\n",
    "    with open('count_untrustworthy.txt', 'a') as f:\n",
    "        f.write(f'{sample_iter},{result_count_untrustworthy},{result_count_trustworthy}\\n')\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_original = explainer_original.explain_node(25, new_features_data.x, new_features_data.edge_index)\n",
    "coefs_filtered = explainer_filtered.explain_node(25, trustworthy_features_data.x, trustworthy_features_data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(coefs_original != 0)[0].shape == np.where(coefs_filtered != 0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "\n",
    "for i in new_features_data.test_mask.nonzero().view(-1).tolist():\n",
    "    coefs = explainer.explain_node(i, new_features_data.x, new_features_data.edge_index)\n",
    "    if np.where(coefs != 0)[0].tolist() != []:\n",
    "        print(i)\n",
    "        print(coefs)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = GraphLIME(model, hop=2, rho=0.1, cached=False)\n",
    "\n",
    "probas = model(new_features_data.x, new_features_data.edge_index).exp()\n",
    "coefs = explainer.explain_node(2, new_features_data.x, new_features_data.edge_index)\n",
    "print(coefs, len(coefs))\n",
    "print(np.where(coefs != 0))\n",
    "np.where(coefs != 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(tweet_df[tweet_df['lang'] == 'pt'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "\n",
    "# for node_idx in range(data.x.shape[0]):\n",
    "#     coefs = explainer.explain_node(node_idx, data.x, data.edge_index)\n",
    "#     if len(set(np.where(coefs != 0)[0]).intersection(set([3,4,5]))) != 0:\n",
    "#         print(node_idx)\n",
    "\n",
    "# try: 102 | 118 | 127\n",
    "node_idx = 91\n",
    "\n",
    "probas = model(new_features_data.x, new_features_data.edge_index).exp()\n",
    "print(probas[node_idx], torch.argmax(probas[node_idx]).item())\n",
    "coefs = explainer.explain_node(node_idx, new_features_data.x, new_features_data.edge_index)\n",
    "\n",
    "print(coefs, len(coefs))\n",
    "print(np.where(coefs != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 91\n",
    "print(tweet_df.loc[k].text)\n",
    "tweet_df.loc[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "claim_df = dataset_mumin.nodes['claim']\n",
    "x = dataset_mumin.rels[('tweet', 'discusses', 'claim')]\n",
    "y = (tweet_df.merge(x, left_index=True, right_on='src')\n",
    "                          .merge(claim_df, left_on='tgt', right_index=True)\n",
    "                          .reset_index(drop=True))\n",
    "\n",
    "y[y['tweet_id'] == 1334273990039375876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "reply_df = dataset_mumin.nodes['reply']\n",
    "reply_quoteof_tweet_df = dataset_mumin.rels[('reply', 'reply_to', 'tweet')]\n",
    "reply_quoteof_tweet_df = (reply_df.merge(quote_of_df, left_index=True, right_on='src')\n",
    "                        .merge(tweet_df, left_on='tgt', right_index=True)\n",
    "                        .reset_index(drop=True))\n",
    "\n",
    "reply_quoteof_tweet_df[reply_quoteof_tweet_df['tweet_id_y'] == 1334273990039375876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer, MultiLabelClassificationExplainer\n",
    "# cls_explainer = SequenceClassificationExplainer(bertweet,tokenizer)\n",
    "cls_explainer = SequenceClassificationExplainer(bertweet,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(normalizeTweet(tweet_df.loc[127].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer.predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(normalizeTweet('Head of Pfizer Research: Covid Vaccine is Female Sterilization ‚Äì Health and Money News https://t.co/IDRLSVmkLz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2)\n",
    "F.softmax(bertweet(torch.tensor([tokenizer.encode(normalizeTweet('my favourite text'))])).logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(bertweet(torch.tensor([tokenizer.encode(normalizeTweet('my favourite text'))])).logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer = SequenceClassificationExplainer(bertweet,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(normalizeTweet(tweet_df.loc[102].text))\n",
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mumin.nodes['claim'].loc[0]['embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mumin.nodes['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_discusses_claim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mumin.nodes['claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('melll')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be8229d8c53a846cb6a0684c036bbbb9278b7b274400c064f315ff8f5b01068c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
