{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "from graphlime import GraphLIME\n",
    "from mumin import MuminDataset\n",
    "\n",
    "import torchmetrics as tm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch_geometric.data import Data as tgData\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from mumin_explainable.architectures.graphs import GAT\n",
    "from mumin_explainable.processor.tweetnormalizer import normalizeTweet\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup mumin graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size= 'small'\n",
    "\n",
    "dataset_mumin = MuminDataset(\n",
    "    twitter_bearer_token=os.getenv('TWITTER_BEARER_TOKEN'),\n",
    "    size=size,\n",
    "    dataset_path=f'./data/datasets/mumin-{size}.zip'\n",
    ")\n",
    "dataset_mumin.compile()\n",
    "mumin_graph = dataset_mumin.to_dgl()\n",
    "mumin_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "metagraph = mumin_graph.metagraph()\n",
    "nx.draw_networkx(metagraph, \n",
    "                 pos=nx.shell_layout(metagraph), \n",
    "                 node_color='white', \n",
    "                 node_size=3000,\n",
    "                 arrows=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel = ('user', 'posted', 'tweet')\n",
    "posted_subgraph = dgl.edge_type_subgraph(mumin_graph, etypes=[rel])\n",
    "train_mask = posted_subgraph.nodes['tweet'].data['train_mask']\n",
    "val_mask = posted_subgraph.nodes['tweet'].data['val_mask']\n",
    "test_mask = posted_subgraph.nodes['tweet'].data['test_mask']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "posted_metagraph = posted_subgraph.metagraph()\n",
    "nx.draw_networkx(posted_metagraph, \n",
    "                 pos=nx.shell_layout(posted_metagraph), \n",
    "                 node_color='white', \n",
    "                 node_size=3000,\n",
    "                 arrows=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_index = torch.cat([\n",
    "    posted_subgraph.edges(etype='posted')[0].unsqueeze(0),\n",
    "    posted_subgraph.edges(etype='posted')[1].unsqueeze(0)\n",
    "], dim=0)\n",
    "data = tgData(\n",
    "    x=posted_subgraph.nodes['tweet'].data['feat'],\n",
    "    y=posted_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=train_mask,\n",
    "    val_mask=val_mask,\n",
    "    test_mask=test_mask,\n",
    "    edge_index=edges_index.long())\n",
    "\n",
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "reply_df = dataset_mumin.nodes['reply']\n",
    "quote_of_df = dataset_mumin.rels[('reply', 'quote_of', 'tweet')]\n",
    "reply_quote_tweet_df = (reply_df.merge(quote_of_df, left_index=True, right_on='src')\n",
    "                          .merge(tweet_df, left_on='tgt', right_index=True)\n",
    "                          .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'input_dim': data.num_node_features,\n",
    "    'hidden_dim': 16,\n",
    "    'output_dim': max(data.y).item() + 1\n",
    "}\n",
    "\n",
    "model = GAT(**hparams).double()\n",
    "\n",
    "lr = 0.005\n",
    "epochs = 400\n",
    "\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "accuracy = tm.Accuracy()\n",
    "stats_score = tm.StatScores()\n",
    "precision_recall = tm.functional.precision_recall\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        acc = accuracy(output[data.train_mask], data.y[data.train_mask])\n",
    "        pr = precision_recall(output[data.train_mask], data.y[data.train_mask])\n",
    "        ss = stats_score(output[data.train_mask], data.y[data.train_mask])\n",
    "        print('Epoch: {:3d}, acc = {:.3f}, pr = {}, ss = {}'.format(epoch, acc, pr, ss))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tm.Accuracy()\n",
    "stats_score = tm.StatScores()#reduce='macro',num_classes=2)\n",
    "precision_recall = tm.functional.precision_recall\n",
    "\n",
    "print('test')\n",
    "acc = accuracy(output[data.test_mask], data.y[data.test_mask])\n",
    "pr = precision_recall(output[data.test_mask], data.y[data.test_mask], average='micro', num_classes=2)\n",
    "ss = stats_score(output[data.test_mask], data.y[data.test_mask])\n",
    "print('Epoch: {:3d}, acc = {:.3f}, pr = {}, ss = {}'.format(epoch, acc, pr, ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_nodes_explanation(model, explainer, data, dataset_mumin):\n",
    "\n",
    "    feature_id_map = {\n",
    "        'num_retweets': 0,\n",
    "        'num_replies': 1,\n",
    "        'num_quote_tweets': 2\n",
    "    }\n",
    "\n",
    "    user_df = dataset_mumin.nodes['user']\n",
    "    tweet_df = dataset_mumin.nodes['tweet']\n",
    "    reply_df = dataset_mumin.nodes['reply']\n",
    "\n",
    "    reply_quoteof_tweet_df = dataset_mumin.rels[('reply', 'quote_of', 'tweet')]\n",
    "    reply_quoteof_tweet_df = (reply_df.merge(quote_of_df, left_index=True, right_on='src')\n",
    "                            .merge(tweet_df, left_on='tgt', right_index=True)\n",
    "                            .reset_index(drop=True))\n",
    "\n",
    "    user_posted_tweet_df = dataset_mumin.rels[('user', 'posted', 'tweet')]\n",
    "    user_posted_tweet_df = (user_df.merge(user_posted_tweet_df, left_index=True, right_on='src')\n",
    "                            .merge(tweet_df, left_on='tgt', right_index=True)\n",
    "                            .reset_index(drop=True))\n",
    "\n",
    "    user_posted_reply_df = dataset_mumin.rels[('user', 'posted', 'reply')]\n",
    "    user_posted_reply_df = (user_df.merge(user_posted_reply_df, left_index=True, right_on='src')\n",
    "                            .merge(tweet_df, left_on='tgt', right_index=True)\n",
    "                            .reset_index(drop=True))\n",
    "\n",
    "    for node_idx in range(data.x.shape[0]):\n",
    "        \n",
    "        coefs = explainer.explain_node(node_idx, data.x, data.edge_index)\n",
    "        probas = model(data.x, data.edge_index).exp()\n",
    "        # fact_or_fake = 'fact' if torch.argmax(probas[node_idx]).item() == 0 else 'fake'\n",
    "\n",
    "        if tweet_df.iloc[node_idx]['num_quote_tweets'] != 0 and \\\n",
    "            feature_id_map['num_quote_tweets'] not in list(np.where(coefs != 0)[0]): # get only inferences explained by quotes\n",
    "\n",
    "            tgt_tweet_id = dataset_mumin.nodes['tweet'].iloc[node_idx]['tweet_id']\n",
    "\n",
    "            # manual traverse\n",
    "            replies_src = list(reply_quoteof_tweet_df.query(f'tweet_id_y == {tgt_tweet_id}')['src'])                      \n",
    "            quoters_ids = list(user_posted_reply_df.query(f'tgt in {str(replies_src)}')['user_id'])\n",
    "            quoters_posts = user_posted_tweet_df[user_posted_tweet_df['user_id'].isin(quoters_ids)]\n",
    "\n",
    "            if not quoters_posts.empty:\n",
    "                # print(fact_or_fake, quoters_ids)\n",
    "                print(quoters_ids)\n",
    "                # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = dataset_mumin.nodes['user']\n",
    "explainer = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "get_all_nodes_explanation(model, explainer, data, dataset_mumin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance with text-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "TEXT_DIM = 3\n",
    "# bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "# bertweet = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2)\n",
    "bertweet = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetencoder(x, text_dim):\n",
    "    try:\n",
    "        x = bertweet(torch.tensor([tokenizer.encode(normalizeTweet(x))])).pooler_output\n",
    "    except RuntimeError:\n",
    "        x = bertweet(torch.tensor([tokenizer.encode('')])).pooler_output\n",
    "    \n",
    "    return nn.Linear(768, text_dim)(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweet_df['text_encoding'] = tweet_df['text'].apply(lambda x: tweetencoder(x))\n",
    "tweet_df['text_encoding'] = str([0] * TEXT_DIM)\n",
    "for i in range(len(tweet_df)):\n",
    "    try:\n",
    "        tweet_df.loc[i,'text_encoding'] = str(tweetencoder(tweet_df.loc[i]['text'], TEXT_DIM))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding_columns = [f'emb{i}' for i in range(TEXT_DIM)]\n",
    "\n",
    "tweet_embeddings_split_df = pd.DataFrame(\n",
    "    [eval(x) for x in tweet_df['text_encoding'].tolist()],\n",
    "    index=tweet_df.index,\n",
    "    columns=new_embedding_columns\n",
    ")\n",
    "tweet_df = pd.concat([tweet_df, tweet_embeddings_split_df], axis=1)\n",
    "display(tweet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_df = pd.DataFrame(index=range(posted_subgraph.nodes['tweet'].data['feat'].shape[0]))\n",
    "new_features_df = new_features_df.join(tweet_df[new_embedding_columns]).fillna(0)\n",
    "new_features_tensor = torch.tensor(new_features_df.values).double()\n",
    "mixed_features = new_features_tensor#torch.cat([posted_subgraph.nodes['tweet'].data['feat'], new_features_tensor], axis = 1).double()\n",
    "\n",
    "edges_index = torch.cat([\n",
    "    posted_subgraph.edges(etype='posted')[0].unsqueeze(0),\n",
    "    posted_subgraph.edges(etype='posted')[1].unsqueeze(0)\n",
    "], dim=0)\n",
    "new_features_data = tgData(\n",
    "    x=mixed_features,\n",
    "    y=posted_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=posted_subgraph.nodes['tweet'].data['train_mask'],\n",
    "    val_mask=posted_subgraph.nodes['tweet'].data['val_mask'],\n",
    "    test_mask=posted_subgraph.nodes['tweet'].data['test_mask'],\n",
    "    edge_index=edges_index.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'input_dim': new_features_data.num_node_features,\n",
    "    'hidden_dim': 16,\n",
    "    'output_dim': max(new_features_data.y).item() + 1\n",
    "}\n",
    "\n",
    "model = GAT(**hparams).double()\n",
    "\n",
    "lr = 0.005\n",
    "epochs = 400\n",
    "\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "accuracy = tm.Accuracy()\n",
    "precision_recall = tm.functional.precision_recall\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(new_features_data.x, new_features_data.edge_index)\n",
    "    loss = F.nll_loss(output[new_features_data.train_mask], new_features_data.y[new_features_data.train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        acc = accuracy(output[new_features_data.train_mask], new_features_data.y[new_features_data.train_mask])\n",
    "        pr = precision_recall(output[new_features_data.train_mask], new_features_data.y[new_features_data.train_mask])\n",
    "        print('Epoch: {:3d}, acc = {:.3f}, pr = {}'.format(epoch, acc, pr))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tm.Accuracy()\n",
    "stats_score = tm.StatScores()#reduce='macro',num_classes=2)\n",
    "precision_recall = tm.functional.precision_recall\n",
    "f1_score = tm.classification.f_beta.F1Score(num_classes=2, average='none')\n",
    "\n",
    "print('test')\n",
    "acc = accuracy(output[new_features_data.test_mask], new_features_data.y[new_features_data.test_mask])\n",
    "pr = precision_recall(output[new_features_data.test_mask], new_features_data.y[new_features_data.test_mask], average='micro', num_classes=2)\n",
    "ss = stats_score(output[new_features_data.test_mask], new_features_data.y[new_features_data.test_mask])\n",
    "f1 = f1_score(output[new_features_data.test_mask], new_features_data.y[new_features_data.test_mask])\n",
    "print('Epoch: {:3d}, acc = {:.3f}, pr = {}, f1 = {}, ss = {}'.format(epoch, acc, pr, f1, ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "\n",
    "# for node_idx in range(data.x.shape[0]):\n",
    "#     coefs = explainer.explain_node(node_idx, data.x, data.edge_index)\n",
    "#     if len(set(np.where(coefs != 0)[0]).intersection(set([3,4,5]))) != 0:\n",
    "#         print(node_idx)\n",
    "\n",
    "# try: 102 | 118 | 127\n",
    "node_idx = 420\n",
    "\n",
    "probas = model(new_features_data.x, new_features_data.edge_index).exp()\n",
    "print(probas[node_idx], torch.argmax(probas[node_idx]).item())\n",
    "coefs = explainer.explain_node(node_idx, new_features_data.x, new_features_data.edge_index)\n",
    "\n",
    "print(coefs, len(coefs))\n",
    "print(np.where(coefs != 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 205\n",
    "print(tweet_df.loc[k].text)\n",
    "tweet_df.loc[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "claim_df = dataset_mumin.nodes['claim']\n",
    "x = dataset_mumin.rels[('tweet', 'discusses', 'claim')]\n",
    "y = (tweet_df.merge(x, left_index=True, right_on='src')\n",
    "                          .merge(claim_df, left_on='tgt', right_index=True)\n",
    "                          .reset_index(drop=True))\n",
    "\n",
    "y[y['tweet_id'] == 1334273990039375876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "reply_df = dataset_mumin.nodes['reply']\n",
    "reply_quoteof_tweet_df = dataset_mumin.rels[('reply', 'reply_to', 'tweet')]\n",
    "reply_quoteof_tweet_df = (reply_df.merge(quote_of_df, left_index=True, right_on='src')\n",
    "                        .merge(tweet_df, left_on='tgt', right_index=True)\n",
    "                        .reset_index(drop=True))\n",
    "\n",
    "reply_quoteof_tweet_df[reply_quoteof_tweet_df['tweet_id_y'] == 1334273990039375876]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer, MultiLabelClassificationExplainer\n",
    "# cls_explainer = SequenceClassificationExplainer(bertweet,tokenizer)\n",
    "cls_explainer = SequenceClassificationExplainer(bertweet,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(normalizeTweet(tweet_df.loc[127].text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer.predicted_class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(normalizeTweet('Head of Pfizer Research: Covid Vaccine is Female Sterilization â€“ Health and Money News https://t.co/IDRLSVmkLz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet = AutoModelForSequenceClassification.from_pretrained(\"vinai/bertweet-base\", num_labels=2)\n",
    "F.softmax(bertweet(torch.tensor([tokenizer.encode(normalizeTweet('my favourite text'))])).logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(bertweet(torch.tensor([tokenizer.encode(normalizeTweet('my favourite text'))])).logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_explainer = SequenceClassificationExplainer(bertweet,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attributions = cls_explainer(normalizeTweet(tweet_df.loc[102].text))\n",
    "cls_explainer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mumin.nodes['claim'].loc[0]['embedding'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mumin.nodes['tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bertweet.config.id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('melll')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be8229d8c53a846cb6a0684c036bbbb9278b7b274400c064f315ff8f5b01068c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
