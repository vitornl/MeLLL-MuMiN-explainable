{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import warnings\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import dgl.nn.pytorch as dglnn\n",
    "\n",
    "from graphlime import GraphLIME\n",
    "from mumin import MuminDataset\n",
    "\n",
    "import torchmetrics as tm\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from torch_geometric.data import Data as tgData\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "from mumin_explainable.architectures.graphs import GAT\n",
    "from mumin_explainable.processor.tweetnormalizer import normalizeTweet\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "_= torch.manual_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup mumin graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size= 'small'\n",
    "dataset_mumin = MuminDataset(\n",
    "    twitter_bearer_token=os.getenv('TWITTER_BEARER_TOKEN'),\n",
    "    size=size,\n",
    "    dataset_path=f'./data/datasets/mumin-{size}.zip'\n",
    ")\n",
    "dataset_mumin.compile()\n",
    "mumin_graph = dataset_mumin.to_dgl()\n",
    "mumin_graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = dataset_mumin.nodes['user']\n",
    "tweet_df = dataset_mumin.nodes['tweet']\n",
    "\n",
    "user_posted_tweet_df = dataset_mumin.rels[('user', 'posted', 'tweet')]\n",
    "user_posted_tweet_subgraph = dgl.edge_type_subgraph(mumin_graph, etypes=[('user', 'posted', 'tweet')])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = 'multilingual'\n",
    "tweet_ds_copy = dataset_mumin.nodes['tweet'].dropna()\n",
    "lang_tweets = (tweet_ds_copy['lang'] == LANG).to_list()\n",
    "del(tweet_ds_copy)\n",
    "\n",
    "if LANG == 'multilingual':\n",
    "    lang_tweets = [True] * len(lang_tweets)\n",
    "tweet_train_mask = user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets)\n",
    "tweet_val_mask = user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets)\n",
    "tweet_test_mask = user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_index = torch.cat([\n",
    "    user_posted_tweet_subgraph.edges(etype='posted')[0].unsqueeze(0),\n",
    "    user_posted_tweet_subgraph.edges(etype='posted')[1].unsqueeze(0)\n",
    "], dim=0)\n",
    "graph_data = tgData(\n",
    "    x=user_posted_tweet_subgraph.nodes['tweet'].data['feat'],\n",
    "    y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=tweet_train_mask,\n",
    "    val_mask=tweet_val_mask,\n",
    "    test_mask=tweet_test_mask,\n",
    "    edge_index=edge_index.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhance with text-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_DIM = 100\n",
    "\n",
    "LANG_TOOL_MAP = {\n",
    "    'multilingual': {\n",
    "        'bertweet': AutoModel.from_pretrained('vinai/bertweet-base'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('vinai/bertweet-base', use_fast=False)\n",
    "    },\n",
    "    'en': {\n",
    "        'bertweet': AutoModel.from_pretrained('vinai/bertweet-base'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('vinai/bertweet-base', use_fast=False)\n",
    "    },\n",
    "    'pt': {\n",
    "        'bertweet': AutoModel.from_pretrained('melll-uff/bertweetbr'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('melll-uff/bertweetbr', normalization=True)\n",
    "    },\n",
    "    'es': {\n",
    "        'bertweet': AutoModel.from_pretrained('pysentimiento/robertuito-base-cased'),\n",
    "        'tokenizer': AutoTokenizer.from_pretrained('pysentimiento/robertuito-base-cased')\n",
    "    }\n",
    "}\n",
    "\n",
    "bertweet = LANG_TOOL_MAP[LANG]['bertweet']\n",
    "tokenizer = LANG_TOOL_MAP[LANG]['tokenizer']\n",
    "\n",
    "def tweetencoder(x, text_dim):\n",
    "    try:\n",
    "        x = bertweet(torch.tensor([tokenizer.encode(normalizeTweet(x))])).pooler_output\n",
    "    except:\n",
    "        x = bertweet(torch.tensor([tokenizer.encode('')])).pooler_output\n",
    "    return nn.Linear(768, text_dim)(x).tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df['text_encoding'] = str([0] * TEXT_DIM)\n",
    "if LANG == 'multilingual':\n",
    "    tweet_df['text_encoding'] = [tweetencoder(text, TEXT_DIM) for text in tweet_df['text']]\n",
    "else:\n",
    "    tweet_df['text_encoding'] = [tweetencoder(text, TEXT_DIM) if lang == LANG else str([0] * TEXT_DIM) for text,lang in zip(tweet_df['text'], tweet_df['lang'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding_columns = [f'emb{i}' for i in range(TEXT_DIM)]\n",
    "\n",
    "tweet_embeddings_split_df = pd.DataFrame(\n",
    "    [x if not isinstance(x, str) else eval(x) for x in tweet_df['text_encoding'].tolist()],\n",
    "    index=tweet_df.index,\n",
    "    columns=new_embedding_columns\n",
    ")\n",
    "tweet_df = pd.concat([tweet_df, tweet_embeddings_split_df], axis=1)\n",
    "tweet_df.dropna(inplace=True)\n",
    "display(tweet_df)\n",
    "\n",
    "text_features_df = pd.DataFrame(index=range(graph_data.x.shape[0]))\n",
    "text_features_df = text_features_df.join(tweet_df[new_embedding_columns])#.fillna(0)\n",
    "text_features_tensor = torch.tensor(text_features_df.values).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODE = 'text'\n",
    "\n",
    "if MODE == 'graph':\n",
    "    modality_features = graph_data.x\n",
    "elif MODE == 'text':\n",
    "    modality_features = text_features_tensor\n",
    "else: # multimodal\n",
    "    modality_features = torch.cat([graph_data.x, text_features_tensor], axis=1).double()\n",
    "\n",
    "modality_data = tgData(\n",
    "    x=modality_features,\n",
    "    y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets),\n",
    "    val_mask=user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets),\n",
    "    test_mask=user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets),\n",
    "    edge_index=graph_data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate new noisy features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_ID = uuid.uuid4().hex\n",
    "PER_NOISY = 0.0 # [0.0, 0.01, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "NUM_NOISY_FEATURES = int(modality_data.x.shape[1] * PER_NOISY)\n",
    "\n",
    "noisy_features = torch.randn((modality_data.x.shape[0], NUM_NOISY_FEATURES))\n",
    "noisy_features = noisy_features - noisy_features.mean(1, keepdim=True)\n",
    "\n",
    "noisy_features_data = tgData(\n",
    "    x=torch.cat([modality_data.x, noisy_features], dim=-1),\n",
    "    y=user_posted_tweet_subgraph.nodes['tweet'].data['label'],\n",
    "    train_mask=user_posted_tweet_subgraph.nodes['tweet'].data['train_mask'] & torch.tensor(lang_tweets),\n",
    "    val_mask=user_posted_tweet_subgraph.nodes['tweet'].data['val_mask'] & torch.tensor(lang_tweets),\n",
    "    test_mask=user_posted_tweet_subgraph.nodes['tweet'].data['test_mask'] & torch.tensor(lang_tweets),\n",
    "    edge_index=modality_data.edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train nosy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {\n",
    "    'input_dim': noisy_features_data.num_node_features,\n",
    "    'hidden_dim': 16,\n",
    "    'output_dim': max(noisy_features_data.y).item() + 1\n",
    "}\n",
    "\n",
    "MODEL_NAME = f'{LANG}_{MODE}_nosy'\n",
    "\n",
    "model = GAT(**hparams).double()\n",
    "\n",
    "lr = 0.005\n",
    "epochs = 400\n",
    "\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "accuracy = tm.Accuracy(task='multiclass', num_classes=2, average='none')\n",
    "stats_score = tm.StatScores(task='multiclass', num_classes=2, average='none')\n",
    "precision = tm.Precision(task='multiclass', num_classes=2, average='none')\n",
    "recall = tm.Recall(task='multiclass', num_classes=2, average='none')\n",
    "f1_score = tm.classification.f_beta.F1Score(task='multiclass', num_classes=2, average='none')\n",
    "best_f1macro = -1\n",
    "\n",
    "bootstrap = tm.BootStrapper(\n",
    "    f1_score, num_bootstraps=200, sampling_strategy='multinomial', quantile=torch.tensor([0.05, 0.95])\n",
    ")\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(noisy_features_data.x, noisy_features_data.edge_index)\n",
    "    loss = F.nll_loss(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    f1 = f1_score(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask])\n",
    "    f1macro = torch.mean(f1)\n",
    "\n",
    "    bootstrap.update(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask])\n",
    "\n",
    "    if f1macro > best_f1macro:\n",
    "        best_f1macro = f1macro\n",
    "        torch.save(model.state_dict(), f'./data/models/{MODEL_NAME}.pth')\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        metrics = {\n",
    "            'Epoch': epoch,\n",
    "            'Accuracy': accuracy(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask]),\n",
    "            'Precision': precision(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask]),\n",
    "            'Recall': recall(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask]),\n",
    "            'Stats_Score': stats_score(output[noisy_features_data.train_mask], noisy_features_data.y[noisy_features_data.train_mask]),\n",
    "            'F1': f1,\n",
    "            'F1-macro': f1macro,\n",
    "            'Bootstrap': bootstrap.compute()\n",
    "        }\n",
    "        print(metrics)\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval noisy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(f'./data/models/{MODEL_NAME}.pth'))\n",
    "model.eval()\n",
    "\n",
    "accuracy = tm.Accuracy(task='multiclass', num_classes=2, average='none')\n",
    "stats_score = tm.StatScores(task='multiclass', num_classes=2, average='none')\n",
    "precision = tm.Precision(task='multiclass', num_classes=2, average='none')\n",
    "recall = tm.Recall(task='multiclass', num_classes=2, average='none')\n",
    "f1_score = tm.classification.f_beta.F1Score(task='multiclass', num_classes=2, average='none')\n",
    "\n",
    "print('test')\n",
    "\n",
    "output = model(noisy_features_data.x, noisy_features_data.edge_index)\n",
    "\n",
    "f1 = f1_score(output[noisy_features_data.test_mask], noisy_features_data.y[noisy_features_data.test_mask])\n",
    "f1macro = torch.mean(f1)\n",
    "\n",
    "metrics = {\n",
    "    'Accuracy': accuracy(output[noisy_features_data.test_mask], noisy_features_data.y[noisy_features_data.test_mask]),\n",
    "    'Precision': precision(output[noisy_features_data.test_mask], noisy_features_data.y[noisy_features_data.test_mask]),\n",
    "    'Recall': recall(output[noisy_features_data.test_mask], noisy_features_data.y[noisy_features_data.test_mask]),\n",
    "    'Stats_Score': stats_score(output[noisy_features_data.test_mask], noisy_features_data.y[noisy_features_data.test_mask]),\n",
    "    'F1': f1,\n",
    "    'F1-macro': f1macro,\n",
    "    'Bootstrap': bootstrap.compute()\n",
    "}\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphlime = GraphLIME(model, hop=2, rho=0.1, cached=True)\n",
    "test_nodes = np.where(noisy_features_data.test_mask == True)[0]\n",
    "TOP_K = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_noise_feats = []\n",
    "per_noise_feats = []\n",
    "\n",
    "for node_idx in tqdm(test_nodes):\n",
    "\n",
    "    coefs = graphlime.explain_node(int(node_idx), noisy_features_data.x, noisy_features_data.edge_index)\n",
    "\n",
    "    feat_indices = coefs.argsort()[-TOP_K:]\n",
    "    feat_indices = [idx for idx in feat_indices if coefs[idx] > 0.0]\n",
    "    num_noise_feat = sum(idx >= modality_data.x.shape[1] for idx in feat_indices)\n",
    "    num_noise_feats.append(num_noise_feat)\n",
    "    per_noise_feats.append(num_noise_feat / len(feat_indices) if len(feat_indices) > 0 else 0)\n",
    "\n",
    "sns.distplot(num_noise_feats, hist=True, kde=True, color='red')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('./data/results/robustness-v2-jupyter.json', 'r') as f:\n",
    "        robustness_dict = json.load(f)\n",
    "except:\n",
    "    robustness_dict = {}\n",
    "finally:\n",
    "    with open('./data/results/robustness-v2-jupyter.json', 'w') as f:\n",
    "        robustness_dict[EXP_ID] = {\n",
    "            'PER_NOISE': PER_NOISY,\n",
    "            'NUM_NOISE_FEATURES': NUM_NOISY_FEATURES,\n",
    "            'num_noise_feats': [int(x) for x in num_noise_feats],\n",
    "            'avg_num_noise_feats': sum(num_noise_feats)/len(num_noise_feats),\n",
    "            'per_noise_feats': [float(x) for x in per_noise_feats],\n",
    "            'avg_per_noise_feats': sum(per_noise_feats)/len(per_noise_feats),\n",
    "            'modality': MODE,\n",
    "            'language': LANG\n",
    "        }\n",
    "        json.dump(robustness_dict, f)\n",
    "\n",
    "print(robustness_dict[EXP_ID])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joint analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/results/robustness-v2-jupyter.json', 'r') as f:\n",
    "    robustness_dict = json.load(f)\n",
    "\n",
    "robustness_df = pd.DataFrame(robustness_dict).T\n",
    "robustness_df.columns = map(str.upper, robustness_df.columns)\n",
    "robustness_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repensar essa visualização em termos de TPR e FPR (ROC) ou Precision e Recall (PR) ou AUC\n",
    "sns.lineplot(data=robustness_df, x='AVG_PER_NOISE_FEATS', y='PER_NOISE', palette='rocket')\n",
    "sns.lineplot(data=robustness_df, x='PER_NOISE', y='PER_NOISE', palette='rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustness_expand_df = robustness_df.drop(robustness_df[robustness_df['PER_NOISE'] == 0.0].index)\n",
    "robustness_expand_df = robustness_expand_df.explode(['NUM_NOISE_FEATS', 'PER_NOISE_FEATS'])\n",
    "\n",
    "sns.displot(data=robustness_expand_df, x='PER_NOISE_FEATS', kind='kde', label='PER_NOISE', hue='PER_NOISE', fill=True, palette='rocket')\n",
    "sns.displot(data=robustness_expand_df, x='PER_NOISE_FEATS', kde=True, label='PER_NOISE', hue='PER_NOISE', palette='rocket')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('melll')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "be8229d8c53a846cb6a0684c036bbbb9278b7b274400c064f315ff8f5b01068c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
